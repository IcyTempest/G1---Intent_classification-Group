{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Dataset into one File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "def convertToTxt(filename: str):\n",
    "    createDirec(\"raw_data\")\n",
    "    shutil.copy(\"all_data/{}.csv\".format(filename), \"raw_data/{}.txt\".format(filename))\n",
    "    f = open(\"raw_data/{}.txt\".format(filename), mode=\"r\", encoding=\"utf8\")\n",
    "    oldList = f.readlines()\n",
    "    list = [x.split(\",\")[0] + \"\\n\" for x in oldList]\n",
    "    list = list[1:]\n",
    "    f.close()\n",
    "    f = open(\"raw_data/{}.txt\".format(filename), mode=\"w\", encoding=\"utf8\")\n",
    "    f.writelines(list)\n",
    "    f.close()\n",
    "    print(oldList[1])\n",
    "    print(list[0])\n",
    "\n",
    "\n",
    "def createDirec(directory: str):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        print(\"Success\")\n",
    "    except:\n",
    "        print(\"fail\")\n",
    "\n",
    "def eraseSpaceMode(realFile):\n",
    "    return [f for f in realFile if f.strip()]\n",
    "\n",
    "def majToMAJOR(realFile):\n",
    "    return [re.sub(\"-MAJ\", \"-MAJOR\", f) for f in realFile if f.strip()]\n",
    "\n",
    "\n",
    "def eraseSpace(directory: str):\n",
    "    files = getFileNameFromDir(direc=directory)\n",
    "    for file in files:\n",
    "        realFile = open(\"{}/{}\".format(directory, file), mode=\"r\", encoding=\"UTF-8\")\n",
    "        data = majToMAJOR(realFile)\n",
    "        realFile.close()\n",
    "        realFile = open(\"{}/{}\".format(directory, file), mode=\"w\", encoding=\"UTF-8\")\n",
    "        realFile.writelines(data)\n",
    "        realFile.close()\n",
    "\n",
    "\n",
    "def getFileNameFromDir(direc: str) -> List[str]:\n",
    "    return [f for f in os.listdir(\"{}/\".format(direc))]\n",
    "\n",
    "\n",
    "def restructureFile(direcToScan: str, f: str):\n",
    "    data = pd.read_csv(\"{}/{}\".format(direcToScan, f), encoding=\"UTF-8\")\n",
    "    data.rename(columns=({\"Questions\": \"Question\", \"Intents\": \"Intent\"}), inplace=True)\n",
    "    print(f)\n",
    "    data[\"Question\"].dropna(inplace=True)\n",
    "    if data.isnull().any().any():\n",
    "        print(data.columns())\n",
    "        print(data.isna().sum())\n",
    "        print(data.head())\n",
    "\n",
    "    data.to_csv(\"{}/{}\".format(direcToScan, f), encoding=\"UTF-8\", index=False)\n",
    "    return data\n",
    "\n",
    "\n",
    "def myConcat(direcToScan: str, outputFilename: str, outputDirec: str = \"all_data\"):\n",
    "    files = getFileNameFromDir(direc=direcToScan)\n",
    "\n",
    "    datasets = pd.concat([restructureFile(direcToScan=direcToScan, f=f) for f in files], axis=0, ignore_index=True)\n",
    "\n",
    "    datasets.to_csv(\"{}/{}.csv\".format(outputDirec, outputFilename), index=False)\n",
    "\n",
    "\n",
    "def myOversampling(fileName: str):\n",
    "    temp = pd.read_csv(\"all_data/{}.csv\".format(fileName))\n",
    "\n",
    "    y = temp[\"Intent\"]\n",
    "    X = temp.drop(\"Intent\", axis=1)\n",
    "\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    ros.fit(X, y)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "    newTable = X_resampled\n",
    "    newTable[\"Intent\"] = y_resampled\n",
    "    createDirec(directory=\"oversampling\")\n",
    "    newTable.to_csv(\"oversampling/{}.csv\".format(fileName), index=False)\n",
    "    return newTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScholarshipInfo.csv\n",
      "AskAboutStudyHour.csv\n",
      "AskAboutRegisterDate.csv\n",
      "FindCurrentTime.csv\n",
      "FindAnnouncementInfo.csv\n",
      "AskAboutAge.csv\n",
      "IsMinistryExist.csv\n",
      "AskAboutAccountantRoom.csv\n",
      "AskAboutCarParkingFee.csv\n",
      "ListInstitutionRule.csv\n",
      "AskAboutDormInfo.csv\n",
      "AskAboutSchoolMajors.csv\n",
      "AskAboutInterest.csv\n",
      "AskWorkingDate.csv\n",
      "FindbusStationNearCADT.csv\n",
      "AskaboutFemaleDressCode.csv\n",
      "SchoolMission.csv\n",
      "FindECInfo.csv\n",
      "AskAboutAcademicFee.csv\n",
      "FindTotalStudents.csv\n",
      "AskAboutParkingPrice.csv\n",
      "AskAboutMotocycleParkingFee.csv\n",
      "AskAboutLocation.csv\n",
      "AskAboutEnrollmentRequirement.csv\n",
      "IsCanteenExist.csv\n",
      "AskAboutProvince.csv\n",
      "ListEvent.csv\n",
      "FindClubRoom.csv\n",
      "FindEnrollmentLocation.csv\n",
      "FindClub.csv\n",
      "AskAboutCS_CourseInEachGen.csv\n",
      "FindResearcherRoom.csv\n",
      "AskAboutTN_CourseInEachGen.csv\n",
      "AskWhereHRRoomIs.csv\n",
      "ListClub.csv\n",
      "IsFootballFieldExist.csv\n",
      "SchoolBusInfo.csv\n",
      "AskAboutMinistry.csv\n",
      "AskAboutCompetition.csv\n",
      "ListParkingSpace.csv\n",
      "AskaboutMaleDressCode.csv\n",
      "IsProvinceExist.csv\n",
      "AskWhetherPoepleWorkonExactDate.csv\n",
      "FindTSC.csv\n",
      "AskAboutClubInfo.csv\n",
      "FindCSInfo.csv\n",
      "IsLibraryExist.csv\n",
      "AskWhetherJobAnnoucementExist.csv\n",
      "AskAboutEC_CourseInEachGen.csv\n",
      "FindTNInfo.csv\n",
      "IsExistDoorExit.csv\n",
      "AskHowToComplain.csv\n",
      "WhyShouldChooseCADT.csv\n",
      "ScholarshipInfo.csv\n",
      "AskAboutStudyHour.csv\n",
      "AskAboutRegisterDate.csv\n",
      "FindCurrentTime.csv\n",
      "FindAnnouncementInfo.csv\n",
      "AskAboutAge.csv\n",
      "IsMinistryExist.csv\n",
      "AskAboutAccountantRoom.csv\n",
      "AskAboutCarParkingFee.csv\n",
      "ListInstitutionRule.csv\n",
      "AskAboutDormInfo.csv\n",
      "AskAboutSchoolMajors.csv\n",
      "AskAboutInterest.csv\n",
      "AskWorkingDate.csv\n",
      "FindbusStationNearCADT.csv\n",
      "AskaboutFemaleDressCode.csv\n",
      "SchoolMission.csv\n",
      "FindECInfo.csv\n",
      "AskAboutAcademicFee.csv\n",
      "FindTotalStudents.csv\n",
      "AskAboutParkingPrice.csv\n",
      "AskAboutMotocycleParkingFee.csv\n",
      "AskAboutLocation.csv\n",
      "AskAboutEnrollmentRequirement.csv\n",
      "IsCanteenExist.csv\n",
      "AskAboutProvince.csv\n",
      "ListEvent.csv\n",
      "FindClubRoom.csv\n",
      "FindEnrollmentLocation.csv\n",
      "FindClub.csv\n",
      "AskAboutCS_CourseInEachGen.csv\n",
      "FindResearcherRoom.csv\n",
      "AskAboutTN_CourseInEachGen.csv\n",
      "AskWhereHRRoomIs.csv\n",
      "ListClub.csv\n",
      "IsFootballFieldExist.csv\n",
      "SchoolBusInfo.csv\n",
      "AskAboutMinistry.csv\n",
      "AskAboutCompetition.csv\n",
      "ListParkingSpace.csv\n",
      "AskaboutMaleDressCode.csv\n",
      "IsProvinceExist.csv\n",
      "AskWhetherPoepleWorkonExactDate.csv\n",
      "FindTSC.csv\n",
      "AskAboutClubInfo.csv\n",
      "FindCSInfo.csv\n",
      "IsLibraryExist.csv\n",
      "AskWhetherJobAnnoucementExist.csv\n",
      "AskAboutEC_CourseInEachGen.csv\n",
      "FindTNInfo.csv\n",
      "IsExistDoorExit.csv\n",
      "AskHowToComplain.csv\n",
      "WhyShouldChooseCADT.csv\n",
      "ScholarshipInfo.csv\n",
      "AskAboutStudyHour.csv\n",
      "AskAboutRegisterDate.csv\n",
      "FindCurrentTime.csv\n",
      "FindAnnouncementInfo.csv\n",
      "AskAboutAge.csv\n",
      "IsMinistryExist.csv\n",
      "AskAboutAccountantRoom.csv\n",
      "AskAboutCarParkingFee.csv\n",
      "ListInstitutionRule.csv\n",
      "AskAboutDormInfo.csv\n",
      "AskAboutSchoolMajors.csv\n",
      "AskAboutInterest.csv\n",
      "AskWorkingDate.csv\n",
      "FindbusStationNearCADT.csv\n",
      "AskaboutFemaleDressCode.csv\n",
      "SchoolMission.csv\n",
      "FindECInfo.csv\n",
      "AskAboutAcademicFee.csv\n",
      "FindTotalStudents.csv\n",
      "AskAboutParkingPrice.csv\n",
      "AskAboutMotocycleParkingFee.csv\n",
      "AskAboutLocation.csv\n",
      "AskAboutEnrollmentRequirement.csv\n",
      "IsCanteenExist.csv\n",
      "AskAboutProvince.csv\n",
      "ListEvent.csv\n",
      "FindClubRoom.csv\n",
      "FindEnrollmentLocation.csv\n",
      "FindClub.csv\n",
      "AskAboutCS_CourseInEachGen.csv\n",
      "FindResearcherRoom.csv\n",
      "AskAboutTN_CourseInEachGen.csv\n",
      "AskWhereHRRoomIs.csv\n",
      "ListClub.csv\n",
      "IsFootballFieldExist.csv\n",
      "SchoolBusInfo.csv\n",
      "AskAboutMinistry.csv\n",
      "AskAboutCompetition.csv\n",
      "ListParkingSpace.csv\n",
      "AskaboutMaleDressCode.csv\n",
      "IsProvinceExist.csv\n",
      "AskWhetherPoepleWorkonExactDate.csv\n",
      "FindTSC.csv\n",
      "AskAboutClubInfo.csv\n",
      "FindCSInfo.csv\n",
      "IsLibraryExist.csv\n",
      "AskWhetherJobAnnoucementExist.csv\n",
      "AskAboutEC_CourseInEachGen.csv\n",
      "FindTNInfo.csv\n",
      "IsExistDoorExit.csv\n",
      "AskHowToComplain.csv\n",
      "WhyShouldChooseCADT.csv\n",
      "ScholarshipInfo.csv\n",
      "AskAboutStudyHour.csv\n",
      "AskAboutRegisterDate.csv\n",
      "FindCurrentTime.csv\n",
      "FindAnnouncementInfo.csv\n",
      "AskAboutAge.csv\n",
      "IsMinistryExist.csv\n",
      "AskAboutAccountantRoom.csv\n",
      "AskAboutCarParkingFee.csv\n",
      "ListInstitutionRule.csv\n",
      "AskAboutDormInfo.csv\n",
      "AskAboutSchoolMajors.csv\n",
      "AskAboutInterest.csv\n",
      "AskWorkingDate.csv\n",
      "FindbusStationNearCADT.csv\n",
      "AskaboutFemaleDressCode.csv\n",
      "SchoolMission.csv\n",
      "FindECInfo.csv\n",
      "AskAboutAcademicFee.csv\n",
      "FindTotalStudents.csv\n",
      "AskAboutParkingPrice.csv\n",
      "AskAboutMotocycleParkingFee.csv\n",
      "AskAboutLocation.csv\n",
      "AskAboutEnrollmentRequirement.csv\n",
      "IsCanteenExist.csv\n",
      "AskAboutProvince.csv\n",
      "ListEvent.csv\n",
      "FindClubRoom.csv\n",
      "FindEnrollmentLocation.csv\n",
      "FindClub.csv\n",
      "AskAboutCS_CourseInEachGen.csv\n",
      "FindResearcherRoom.csv\n",
      "AskAboutTN_CourseInEachGen.csv\n",
      "AskWhereHRRoomIs.csv\n",
      "ListClub.csv\n",
      "IsFootballFieldExist.csv\n",
      "SchoolBusInfo.csv\n",
      "AskAboutMinistry.csv\n",
      "AskAboutCompetition.csv\n",
      "ListParkingSpace.csv\n",
      "AskaboutMaleDressCode.csv\n",
      "IsProvinceExist.csv\n",
      "AskWhetherPoepleWorkonExactDate.csv\n",
      "FindTSC.csv\n",
      "AskAboutClubInfo.csv\n",
      "FindCSInfo.csv\n",
      "IsLibraryExist.csv\n",
      "AskWhetherJobAnnoucementExist.csv\n",
      "AskAboutEC_CourseInEachGen.csv\n",
      "FindTNInfo.csv\n",
      "IsExistDoorExit.csv\n",
      "AskHowToComplain.csv\n",
      "WhyShouldChooseCADT.csv\n"
     ]
    }
   ],
   "source": [
    "## Concatenate All Dataset into one File\n",
    "myConcat(direcToScan=\"datasets\", outputFilename=\"all_data_dataset\")\n",
    "\n",
    "## Concatenate All Entity-tag Dataset into one File\n",
    "myConcat(direcToScan=\"entity-tag\", outputFilename=\"all_entity_dataset\")\n",
    "\n",
    "## Concatenate All Segmentation Dataset into one File\n",
    "myConcat(direcToScan=\"segments\", outputFilename=\"all_segment_dataset\")\n",
    "\n",
    "## Concatenate All Segmentation Dataset into one File\n",
    "myConcat(direcToScan=\"POS/\", outputFilename=\"all_pos_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erase blank from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    eraseSpace(directory=\"datasets\")\n",
    "    eraseSpace(directory=\"entity-tag\")\n",
    "    eraseSpace(directory=\"POS\")\n",
    "    eraseSpace(directory=\"segments\")\n",
    "    print(\"Success\")\n",
    "except:\n",
    "    print(\"fail\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied OverSampling to DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTable = myOversampling(fileName=\"all_segment_dataset\")\n",
    "newTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Compare whether there's equal file or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getFileNameFromDir(\"datasets\")\n",
    "seg = getFileNameFromDir(\"segments\")\n",
    "pos = getFileNameFromDir(\"POS\")\n",
    "ent = getFileNameFromDir(\"entity-tag\")\n",
    "if len(data) != len(seg) != len(pos) != len(ent):\n",
    "    print(\"not equal\")\n",
    "    for x in zip(data, seg, pos, ent):\n",
    "        if data != seg != pos != ent:\n",
    "            print(\"data: {} \".format(data))\n",
    "else:\n",
    "    print(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for any null or space data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNullOrSpace():\n",
    "    count: int = 0\n",
    "    checkDict: Dict[str, List[str]] = {\n",
    "        \"datasets\": getFileNameFromDir(\"datasets\"),\n",
    "        \"segments\": getFileNameFromDir(\"segments\"),\n",
    "        \"pos\": getFileNameFromDir(\"pos\"),\n",
    "        \"entity-tag\": getFileNameFromDir(\"entity-tag\"),\n",
    "    }\n",
    "\n",
    "    for direc, v in checkDict.items():\n",
    "        for filename in v:\n",
    "            data = pd.read_csv(\"{}/{}\".format(direc, filename))\n",
    "            if data.isnull().any().any():\n",
    "                print(\"{} file of direc {} have null at:\".format(filename, direc))\n",
    "                print(data[data[\"Question\"].isnull()])\n",
    "                count += 1\n",
    "\n",
    "    if count == 0:\n",
    "        print(\"No null sentence in any files detected\")\n",
    "\n",
    "\n",
    "checkNullOrSpace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Ner length, POS length, and SEG Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "# def findDiffLengthSentence(allSegDataset: DataFrame, allEntityDataset: DataFrame, allPosDataset: DataFrame):\n",
    "#     myTempDict = {}\n",
    "#     indexs = allEntityDataset.index.tolist()\n",
    "#     segs = allSegDataset[\"Question\"].to_list()\n",
    "#     tags = allSegDataset[\"Intent\"].to_list()\n",
    "#     ents = allEntityDataset[\"Question\"].to_list()\n",
    "#     poss = allPosDataset[\"Question\"].to_list()\n",
    "#\n",
    "#     for seg, tag, ent, pos, index in zip(segs, tags, ents, poss, indexs):\n",
    "#         if len(str(seg).split()) is not len(str(pos).split()) is not len(str(ent).split()):\n",
    "#             myTempDict.setdefault(\"index\", []).append(index)\n",
    "#             myTempDict.setdefault(\"intent\", []).append(tag)\n",
    "#             myTempDict.setdefault(\"length_seg\", []).append(len(str(seg).split()))\n",
    "#             myTempDict.setdefault(\"length_pos\", []).append(len(str(pos).split()))\n",
    "#             myTempDict.setdefault(\"length_ent\", []).append(len(str(ent).split()))\n",
    "#             myTempDict.setdefault(\"seg\", []).append(seg)\n",
    "#             myTempDict.setdefault(\"pos\", []).append(pos)\n",
    "#             myTempDict.setdefault(\"ent\", []).append(ent)\n",
    "#\n",
    "#     errorPd = pd.DataFrame.from_dict(myTempDict)\n",
    "#     errorPd.to_csv(\"all_data/diff_length_sentences.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"POS/AskWhereHRRoomIs.csv\")\n",
    "# temp.head()\n",
    "temp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSegFileName = getFileNameFromDir(direc=\"segments\")\n",
    "# allPosFileName = getFileNameFromDir(direc=\"pos\")\n",
    "# allEntityFileName = getFileNameFromDir(direc=\"entity-tag\")\n",
    "\n",
    "myTempDict = {}\n",
    "ree = \"\"\n",
    "# Loop Through each file name to read csv\n",
    "for file in allSegFileName:\n",
    "    file = file.replace(\" \", \"\")\n",
    "    allEntityDataset = pd.read_csv(\"entity-tag/{}\".format(file))\n",
    "    allPosDataset = pd.read_csv(\"POS/{}\".format(file))\n",
    "    allSegDataset = pd.read_csv(\"segments/{}\".format(file))\n",
    "    if allEntityDataset[\"Intent\"][0] != ree:\n",
    "        ree = allEntityDataset[\"Intent\"][0]\n",
    "        print(ree)\n",
    "\n",
    "    indexs = allEntityDataset.index.tolist()\n",
    "    segs = allSegDataset[\"Question\"].to_list()\n",
    "    tags = allSegDataset[\"Intent\"].to_list()\n",
    "    ents = allEntityDataset[\"Question\"].to_list()\n",
    "    poss = allPosDataset[\"Question\"].to_list()\n",
    "\n",
    "    # loop through the csv to find wrong sentence length\n",
    "    for seg, tag, ent, pos, index in zip(segs, tags, ents, poss, indexs):\n",
    "        lengthEnt = len(str(ent).split())\n",
    "        lengthSeg = len(str(seg).split())\n",
    "        lengthPos = len(str(seg).split())\n",
    "        if lengthSeg != lengthPos or lengthSeg != lengthEnt:\n",
    "            myTempDict.setdefault(\"index\", []).append(index)\n",
    "            myTempDict.setdefault(\"intent\", []).append(tag)\n",
    "            myTempDict.setdefault(\"length_seg\", []).append(len(str(seg).split()))\n",
    "            myTempDict.setdefault(\"length_pos\", []).append(len(str(pos).split()))\n",
    "            myTempDict.setdefault(\"length_ent\", []).append(len(str(ent).split()))\n",
    "            myTempDict.setdefault(\"seg\", []).append(seg)\n",
    "            myTempDict.setdefault(\"pos\", []).append(pos)\n",
    "            myTempDict.setdefault(\"ent\", []).append(ent)\n",
    "\n",
    "errorPd = pd.DataFrame.from_dict(myTempDict)\n",
    "errorPd.to_csv(\"all_data/diff_length_sentences.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.errors import EmptyDataError\n",
    "\n",
    "try:\n",
    "    wrongSentence = pd.read_csv(\"all_data/diff_length_sentences.csv\")\n",
    "\n",
    "    print(\"length_seg: \", wrongSentence[\"length_seg\"].count())\n",
    "    print(\"length_pos: \", wrongSentence[\"length_pos\"].count())\n",
    "    print(\"length_ent: \", wrongSentence[\"length_ent\"].count())\n",
    "    print(\"seg: \", wrongSentence[\"seg\"].count())\n",
    "    print(\"pos: \", wrongSentence[\"pos\"].count())\n",
    "    print(\"ent: \", wrongSentence[\"ent\"].count())\n",
    "\n",
    "    print(wrongSentence)\n",
    "except EmptyDataError:\n",
    "    print(\"No Wrong Length Sentences\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Amount of Sentences per intent as well as Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Amount of Sentences\n",
    "allDataset = pd.read_csv(\"all_data/all_data_dataset.csv\")\n",
    "allDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For used to get Gradient color set\n",
    "\n",
    "def getPalleteAndArrangeValue(color: str, size, as_cmap: bool = False):\n",
    "    pal = sns.color_palette(color, len(size), as_cmap=as_cmap)\n",
    "\n",
    "    # First sort of list\n",
    "    rank = size.argsort()\n",
    "\n",
    "    # Second sort where we can now define which should have the brightest color\n",
    "    proper = rank.argsort()\n",
    "\n",
    "    # Convert the tuple to a list, also to arrange the the color according to the size of each index of the list\n",
    "    aray = np.array(pal)[proper]\n",
    "    return aray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find sentences total per intent and Draw BarPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16,8))\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "dataCount = allDataset.groupby(\"Intent\").size()\n",
    "\n",
    "aray = getPalleteAndArrangeValue(color=\"Greens_d\", size=dataCount)\n",
    "\n",
    "ax = sns.barplot(x=dataCount.index.tolist(), y=dataCount.values.tolist(), palette=aray)\n",
    "\n",
    "plt.bar_label(ax.containers[0], padding=5, rotation=90)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "\n",
    "print(dataCount)\n",
    "print(\"-------------------------\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Total\n",
    "print(\"Total Sentence length: \", allDataset.Question.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Max Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"all_data/all_segment_dataset.csv\")\n",
    "\n",
    "temp[\"Question_length\"] = temp[\"Question\"].apply(lambda x: len(x.split(\" \")))\n",
    "print(temp[\"Question_length\"].describe())\n",
    "\n",
    "max = temp[\"Question_length\"].max()\n",
    "\n",
    "print(\"Max Sentence Length: \", max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Max number of Intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"all_data/all_data_dataset.csv\")\n",
    "len(temp[\"Intent\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check amount of entities as well as for any errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entityDataFrame = pd.read_csv(\"all_data/all_entity_dataset.csv\")\n",
    "entityFrame = pd.read_csv(\"Named Entity.csv\")\n",
    "entityFrame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove white space from column name and apply it to csv file\n",
    "# TODO: This is still experimenting, use with caution\n",
    "\n",
    "# entityFrame = entityFrame.rename(columns={entityFrame.columns.values[1]: \"Question\"})\n",
    "# entityFrame.to_csv(\"Named Entity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total amount of entity number\n",
    "entityDataFrame = pd.read_csv(\"all_data/all_entity_dataset.csv\")\n",
    "entityFrame = pd.read_csv(\"Named Entity.csv\")\n",
    "\n",
    "myDict = {}\n",
    "errorDict = {}\n",
    "\n",
    "entityTag = entityFrame[\"NE Code\"].to_list()\n",
    "entitySentences = entityDataFrame[\"Question\"].to_list()\n",
    "\n",
    "for x in entityTag:\n",
    "    count = 0\n",
    "    error = 0\n",
    "    for index, row in entityDataFrame.iterrows():\n",
    "        sentence = row[\"Question\"].split()\n",
    "        for c in range(len(sentence)):\n",
    "            # Matches /B-Word until space\n",
    "            if re.search(r\"/B-{}$\".format(x), sentence[c]):\n",
    "                count += 1\n",
    "                split = sentence[c].rsplit(\"/B-\", maxsplit=1)[1]\n",
    "                myDict.update({split: row[\"Intent\"]})\n",
    "                # myDict.update({split: count})\n",
    "\n",
    "            elif re.search(r\"/B-{}.*[^\\s]\".format(x), sentence[c]):\n",
    "                error += 1\n",
    "                split = sentence[c].rsplit(\"/B-\", maxsplit=1)[1]\n",
    "                errorDict.setdefault(split, []).append(row[\"Intent\"])\n",
    "\n",
    "            if re.search(r\"/I-{}.*[^\\s]\".format(x), sentence[c]):\n",
    "                error += 1\n",
    "                split = sentence[c].rsplit(\"/I-\", maxsplit=1)[1]\n",
    "                errorDict.setdefault(split, []).append(row[\"Intent\"])\n",
    "\n",
    "print(errorDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Search through Punctuation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prt\n",
      "verb\n",
      "adp\n",
      "adv\n",
      "noun\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "entityDataFrame = pd.read_csv(\"all_data/all_pos_dataset.csv\")\n",
    "entityFrame = pd.read_csv(\"pos_structure.csv\")\n",
    "\n",
    "\n",
    "errorDict = {}\n",
    "\n",
    "entityTag = entityFrame[\"pos\"].to_list()\n",
    "entitySentences = entityDataFrame[\"Question\"].to_list()\n",
    "\n",
    "for x in entityTag:\n",
    "    print(x)\n",
    "    count = 0\n",
    "    error = 0\n",
    "    for index, row in entityDataFrame.iterrows():\n",
    "        sentence = row[\"Question\"].split()\n",
    "        for c in range(len(sentence)):\n",
    "            # Matches /B-Word until space\n",
    "            if re.search(r\"/{}[^\\s,]\".format(x), sentence[c]):\n",
    "                error += 1\n",
    "                split = sentence[c].rsplit(\"/\", maxsplit=1)[1]\n",
    "                errorDict.setdefault(split, []).append(row[\"Intent\"])\n",
    "\n",
    "print(errorDict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entityAmount = pd.DataFrame(myDict.items(), columns=[\"Intent\", \"Amount\"])\n",
    "entityAmount.sort_values(by=[\"Amount\"], inplace=True, ascending=False)\n",
    "\n",
    "color = getPalleteAndArrangeValue(\"crest\", entityAmount[\"Amount\"])\n",
    "\n",
    "plt.pie(x=entityAmount[\"Amount\"], labels=entityAmount[\"Intent\"], colors=color, autopct=\"%.2f\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the percentage\n",
    "\n",
    "# Sum of Intent\n",
    "totalIntentTag = sum(myDict[x] for x in myDict)\n",
    "rise = [\"{0:.2f}%\".format(myDict[x] * 100 / totalIntentTag) for x in myDict]\n",
    "\n",
    "entityAmount[\"Percentage\"] = rise\n",
    "entityAmount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count each word occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
